# -*- coding: utf-8 -*-
"""ML_models_iris.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BrK1JZxCeH-u7M_IoQoaq9rJ13iMn6Mq

# Импорт библиотек
"""

# Импорт библиотек
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import seaborn as sns
import matplotlib.pyplot as plt

# Чтение датасета из файла csv
!gdown --id 1vYRrRhMNhIRfJysuOva1BJXk_1N2_J1J
df = pd.read_csv('iris.csv')

"""# Первичный взгляд на датафрейм"""

df.head()

df.info()

"""Как видно выше, пустые значения отсутствуют. Species - целевая переменная, SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm - атрибуты.

Значения Species (Вид цветка) заранее закодированы для дальнейшей обработки. Взглянем на ее уникальные значения:
"""

df.Species.unique()

"""Числовым значениям соответствуют следующие виды цветов: 
* 0 - Setosa
* 1 - Versicolor
* 2 - Virginica

Далее, мы убираем ненужные признаки - id:
* axis=1 - убираем всю колонку целиком;
* inplace=True - производим изменения в df, не создавая новый объект.
"""

df.drop('Id',axis=1,inplace=True)

df.shape

"""# Разведочный анализ

## Таргет

Оценим распределение целевой переменной на предмет перекоса значений
"""

# нормирование на размер датасета
norm_target = (df
               .Species
               .value_counts(normalize=True)
               .mul(100)
               .rename('percent')
               .reset_index())

plt.figure(figsize=(15, 7))
ax = sns.barplot(x='index', y='percent', data=norm_target)

# Вывод значений над графиками - annotate()
# В цикле смотрим каждый столбец графика и на нем отмечаем значения
for p in ax.patches:
    percentage = '{:.1f}%'.format(p.get_height())
    ax.annotate(percentage,  # текст
                (p.get_x() + p.get_width() / 2., p.get_height()),  # координата xy
                ha='center', # центрирование
                va='center',
                xytext=(0, 10),
                textcoords='offset points', # точка смещения относительно координаты
                fontsize=14)

plt.title('Approved', fontsize=20)

plt.xlabel('approved', fontsize=14)
plt.ylabel('Проценты', fontsize=14)

plt.xticks(fontsize=14)
plt.yticks(fontsize=14);

"""## Отношение длины к ширине"""

fig = df[df.Species==0].plot(kind='scatter',x='SepalLengthCm',y='SepalWidthCm',color='orange', label='Setosa')
df[df.Species==1].plot(kind='scatter',x='SepalLengthCm',y='SepalWidthCm',color='blue', label='Versicolor',ax=fig)
df[df.Species==2].plot(kind='scatter',x='SepalLengthCm',y='SepalWidthCm',color='green', label='Virginica', ax=fig)
fig.set_xlabel("Sepal Length")
fig.set_ylabel("Sepal Width")
fig.set_title("Sepal Length VS Width")
fig=plt.gcf()
fig.set_size_inches(10,6)
plt.show()

"""График показывает отношение между длиной и шириной чашелистика цветка. Setosa показывает лучшее групповое разделение, чем две другие разновидности. Посмотрим на отношение между длиной и шириной у лепестков. """

fig = df[df.Species==0].plot(kind='scatter',x='PetalLengthCm',y='PetalWidthCm',color='orange', label='Setosa')
df[df.Species==1].plot(kind='scatter',x='PetalLengthCm',y='PetalWidthCm',color='blue', label='Versicolor',ax=fig)
df[df.Species==2].plot(kind='scatter',x='PetalLengthCm',y='PetalWidthCm',color='green', label='Virginica', ax=fig)
fig.set_xlabel("Petal Length")
fig.set_ylabel("Petal Width")
fig.set_title("Petal Length VS Width")
fig=plt.gcf()
fig.set_size_inches(10,6)
plt.show()

"""Для признаков лепестка наблюдается более лучшее групповое разделение в сравнении с чашелистиком. Это говорит о том, что за счет признаков лепестка можно сформировать более точный прогноз по сравнению с признаками чашелистика.

## Распределение длины и ширины

Взглянем на то, как распределены длина и ширина у листков и чашелистиков.
"""

df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']].hist(edgecolor='black', linewidth=1.2)
fig=plt.gcf()
fig.set_size_inches(16,8)
plt.show()

"""Оценим как длина и ширина варьируются в зависимости от вида"""

plt.figure(figsize=(15,10))
plt.subplot(2,2,1)
sns.violinplot(x='Species',y='SepalLengthCm',data=df)
plt.subplot(2,2,2)
sns.violinplot(x='Species',y='SepalWidthCm',data=df)
plt.subplot(2,2,3)
sns.violinplot(x='Species',y='PetalLengthCm',data=df)
plt.subplot(2,2,4)
sns.violinplot(x='Species',y='PetalWidthCm',data=df)

"""График показывает плотность распределения длины и ширины у вариаций цветков. Чем шире "скрипка" - тем плотнее распределены значения, чем уже - тем менее плотное распределение.

# Обучение модели

Импортируем необходимые библиотеки для различных алгоритмов классификации
"""

from sklearn.linear_model import LogisticRegression  # Для реализации алгоритма  логистической регрессии
from sklearn.model_selection import train_test_split # Для разбиения датасета на train и test
from sklearn.neighbors import KNeighborsClassifier # Алгоритм K ближайших соседей
from sklearn import svm  # Для реализации алгоритма  Метод Опорных Векторов (Support Vector Method)
from sklearn import metrics # Для проверки точности модели
from sklearn.tree import DecisionTreeClassifier # Для реализации алгоритма Деревья решений

"""## Оценка корреляции

Точность модели может быть снижена ввиду корреляции признаков. Оценим степень корреляции с помощью тепловой карты
"""

plt.figure(figsize=(8,4))
# матрица корреляции 
sns.heatmap(df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']].
            corr(),annot=True,cmap='cubehelix_r')
plt.show()

"""Как видно из матрицы ширина и длина чашелистика не коррелированы, а длина и ширина лепестка - имеют высокую степень корреляции.

## Разделение датасета на тренирующую и тестировочную часть

Ниже представлено разделение датасета на тренирующую и тестировочную части, атрибут test_size=0.3 отвечает за разделение датасета на составляющие: 30% - test, 70% - train.
"""

train, test = train_test_split(df, test_size=0.3)

"""Проверим корректность разбиения датасета:"""

train.info()

train.shape

test.shape

"""Создадим переменные, куда будут помещены признаки и целевая переменная для обучающей выборки тестировочной:"""

train_X = train[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]
train_Y = train.Species
test_X = test[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]
test_Y = test.Species

"""## Совместное использование признаков при обучении и тестрированни моделей

### Метод Опорных Векторов (Support Vector Method)
"""

# Создание объекта алгоритма
model = svm.SVC()
# Обучение алгоритма на тренировочных данных 
model.fit(train_X, train_Y)
# Обработка тестировочных данных через обученный алгоритм
prediction = model.predict(test_X)
print('The accuracy of the SVM is', metrics.accuracy_score(prediction, test_Y))

"""### Логистическая регрессия"""

# Создание объекта алгоритма
model = LogisticRegression()
# Обучение алгоритма на тренировочных данных
model.fit(train_X, train_Y)
# Обработка тестировочных данных через обученный алгоритм
prediction = model.predict(test_X)
print('The accuracy of the Logistic Regression is', metrics.accuracy_score(prediction, test_Y))

"""### Деревья решений"""

# Создание объекта алгоритма
model = DecisionTreeClassifier()
# Обучение алгоритма на тренировочных данных
model.fit(train_X, train_Y)
# Обработка тестировочных данных через обученный алгоритм
prediction = model.predict(test_X)
print('The accuracy of the Decision Tree is', metrics.accuracy_score(prediction, test_Y))

"""### K-ближайших соседей"""

# Создание объекта алгоритма
model = KNeighborsClassifier(n_neighbors=6)
# Обучение алгоритма на тренировочных данных
model.fit(train_X, train_Y)
# Обработка тестировочных данных через обученный алгоритм
prediction = model.predict(test_X)
print('The accuracy of the Decision Tree is', metrics.accuracy_score(prediction, test_Y))

"""Оценим влияние изменение значения параметра n_neighbors ( количество соседей для помещения данных в новый класс) на точность работы алгоритма"""

a_index=list(range(1,11))
a=pd.Series()
x=[1,2,3,4,5,6,7,8,9,10]
for i in a_index:
    model=KNeighborsClassifier(n_neighbors=i) 
    model.fit(train_X,train_Y)
    prediction=model.predict(test_X)
    a=a.append(pd.Series(metrics.accuracy_score(prediction,test_Y)))
plt.plot(a_index, a)
plt.xticks(x)

"""Выше представлен график, показывающий точность модели K-ближайших соседей в зависимости от значения параметра n_neighbors

## Раздельное использование признаков при обучении и тестрированни моделей

Создадим отдельные датасеты для чашелистиков и лепестков
"""

petal = df[['PetalLengthCm', 'PetalWidthCm', 'Species']]
sepal = df[['SepalLengthCm', 'SepalWidthCm', 'Species']]

"""Проведем два процесса обучения для двух наборов данных"""

train_p, test_p = train_test_split(petal, test_size=0.3, random_state=0)
train_X_p = train_p[['PetalLengthCm', 'PetalWidthCm']]
train_Y_p = train_p.Species
test_X_p = test_p[['PetalLengthCm', 'PetalWidthCm']]
test_Y_p = test_p.Species


train_s, test_s = train_test_split(sepal, test_size=0.3, random_state=0)
train_X_s = train_s[['SepalLengthCm', 'SepalWidthCm']]
train_Y_s = train_s.Species
test_X_s = test_s[['SepalLengthCm', 'SepalWidthCm']]
test_Y_s = test_s.Species

"""### Метод Опорных Векторов (Support Vector Method)"""

model = svm.SVC()
model.fit(train_X_p, train_Y_p)
prediction = model.predict(test_X_p)
print('The accuracy of the SVM is', metrics.accuracy_score(prediction, test_Y_p))

model = svm.SVC()
model.fit(train_X_s, train_Y_s)
prediction = model.predict(test_X_s)
print('The accuracy of the SVM is', metrics.accuracy_score(prediction, test_Y_s))

"""### Логистическая регрессия"""

model = LogisticRegression()
model.fit(train_X_p, train_Y_p)
prediction = model.predict(test_X_p)
print('The accuracy of the Logistic Regression is', metrics.accuracy_score(prediction, test_Y_p))

model = LogisticRegression()
model.fit(train_X_s, train_Y_s)
prediction = model.predict(test_X_s)
print('The accuracy of the Logistic Regression is', metrics.accuracy_score(prediction, test_Y_s))

"""### Деревья решений"""

model = DecisionTreeClassifier()
model.fit(train_X_p, train_Y_p)
prediction = model.predict(test_X_p)
print('The accuracy of the Decision Tree is', metrics.accuracy_score(prediction, test_Y_p))

model = DecisionTreeClassifier()
model.fit(train_X_s, train_Y_s)
prediction = model.predict(test_X_s)
print('The accuracy of the Decision Tree is', metrics.accuracy_score(prediction, test_Y_s))

"""### K-ближайших соседей"""

model = KNeighborsClassifier(n_neighbors=3)
model.fit(train_X_p, train_Y_p)
prediction = model.predict(test_X_p)
print('The accuracy of the KNN is', metrics.accuracy_score(prediction, test_Y_p))

model = KNeighborsClassifier(n_neighbors=3)
model.fit(train_X_s, train_Y_s)
prediction = model.predict(test_X_s)
print('The accuracy of the KNN is', metrics.accuracy_score(prediction, test_Y_s))

a_index=list(range(1,11))
a=pd.Series()
x=[1,2,3,4,5,6,7,8,9,10]
for i in a_index:
    model = KNeighborsClassifier(n_neighbors=i)
    model.fit(train_X_p, train_Y_p)
    prediction = model.predict(test_X_p)
    print('The accuracy of the KNN is', metrics.accuracy_score(prediction, test_Y_p))
    a=a.append(pd.Series(metrics.accuracy_score(prediction,test_Y_p)))
plt.plot(a_index, a)
plt.xticks(x)

b_index=list(range(1,11))
b=pd.Series()
x=[1,2,3,4,5,6,7,8,9,10]
for i in b_index:
    model = KNeighborsClassifier(n_neighbors=i)
    model.fit(train_X_s, train_Y_s)
    prediction = model.predict(test_X_s)
    print('The accuracy of the KNN is', metrics.accuracy_score(prediction, test_Y_s))
    b=b.append(pd.Series(metrics.accuracy_score(prediction,test_Y_s)))
plt.plot(b_index, b)
plt.xticks(x)

"""# Выводы

* Использование признаков, характеризующих лепесток, дает более высокое значение точности при обработке значений алгоритмами
"""